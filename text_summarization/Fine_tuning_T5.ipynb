{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Shivanandroy/T5-Finetuning-PyTorch/blob/main/notebook/T5_Fine_tuning_with_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bbwl6E1E205R",
    "outputId": "7ab0c99b-8f25-4f48-a74b-ba54bf93c6bf"
   },
   "source": [
    "!pip install sentencepiece\n",
    "!pip install transformers\n",
    "!pip install rich[jupyter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "y6nEben93JAk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"cleaned_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "wB441x104K-o"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import os\n",
    "\n",
    "# Importing the T5 modules from huggingface/transformers\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "from rich.table import Column, Table\n",
    "from rich import box\n",
    "from rich.console import Console\n",
    "\n",
    "# define a rich console logger\n",
    "console=Console(record=True)\n",
    "\n",
    "def display_df(df):\n",
    "\n",
    "  console=Console()\n",
    "  table = Table(Column(\"source_text\", justify=\"center\" ), Column(\"target_text\", justify=\"center\"), title=\"Sample Data\",pad_edge=False, box=box.ASCII)\n",
    "\n",
    "  for i, row in enumerate(df.values.tolist()):\n",
    "    table.add_row(row[0], row[1])\n",
    "\n",
    "  console.print(table)\n",
    "\n",
    "training_logger = Table(Column(\"Epoch\", justify=\"center\" ), \n",
    "                        Column(\"Steps\", justify=\"center\"),\n",
    "                        Column(\"Loss\", justify=\"center\"), \n",
    "                        title=\"Training Status\",pad_edge=False, box=box.ASCII)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tlYaKW9h4ai_"
   },
   "outputs": [],
   "source": [
    "# Setting up the device for GPU usage\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8vLQPGAn4v17"
   },
   "outputs": [],
   "source": [
    "class YourDataSetClass(Dataset):\n",
    "  \"\"\"\n",
    "  Creating a custom dataset for reading the dataset and \n",
    "  loading it into the dataloader to pass it to the neural network for finetuning the model\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, dataframe, tokenizer, source_len, target_len, source_text, target_text):\n",
    "    self.tokenizer = tokenizer\n",
    "    self.data = dataframe\n",
    "    self.source_len = source_len\n",
    "    self.summ_len = target_len\n",
    "    self.target_text = self.data[target_text]\n",
    "    self.source_text = self.data[source_text]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.target_text)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    source_text = str(self.source_text[index])\n",
    "    target_text = str(self.target_text[index])\n",
    "\n",
    "    #cleaning data so as to ensure data is in string type\n",
    "    source_text = ' '.join(source_text.split())\n",
    "    target_text = ' '.join(target_text.split())\n",
    "\n",
    "    source = self.tokenizer.batch_encode_plus([source_text], max_length= self.source_len, pad_to_max_length=True, truncation=True, padding=\"max_length\", return_tensors='pt')\n",
    "    target = self.tokenizer.batch_encode_plus([target_text], max_length= self.summ_len, pad_to_max_length=True, truncation=True, padding=\"max_length\", return_tensors='pt')\n",
    "\n",
    "    source_ids = source['input_ids'].squeeze()\n",
    "    source_mask = source['attention_mask'].squeeze()\n",
    "    target_ids = target['input_ids'].squeeze()\n",
    "    target_mask = target['attention_mask'].squeeze()\n",
    "\n",
    "    return {\n",
    "        'source_ids': source_ids.to(dtype=torch.long), \n",
    "        'source_mask': source_mask.to(dtype=torch.long), \n",
    "        'target_ids': target_ids.to(dtype=torch.long),\n",
    "        'target_ids_y': target_ids.to(dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Nkj6wIMt40RK"
   },
   "outputs": [],
   "source": [
    "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
    "\n",
    "\n",
    "  model.train()\n",
    "  for _,data in enumerate(loader, 0):\n",
    "    y = data['target_ids'].to(device, dtype = torch.long)\n",
    "    y_ids = y[:, :-1].contiguous()\n",
    "    lm_labels = y[:, 1:].clone().detach()\n",
    "    lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "    ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "    mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "    outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n",
    "    loss = outputs[0]\n",
    "\n",
    "    if _%10==0:\n",
    "      training_logger.add_row(str(epoch), str(_), str(loss))\n",
    "      console.print(training_logger)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "GUBykK-A43DF"
   },
   "outputs": [],
   "source": [
    "def validate(epoch, tokenizer, model, device, loader):\n",
    "\n",
    "  \"\"\"\n",
    "  Function to evaluate model for predictions\n",
    "\n",
    "  \"\"\"\n",
    "  model.eval()\n",
    "  predictions = []\n",
    "  actuals = []\n",
    "  with torch.no_grad():\n",
    "      for _, data in enumerate(loader, 0):\n",
    "          y = data['target_ids'].to(device, dtype = torch.long)\n",
    "          ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "          mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "          generated_ids = model.generate(\n",
    "              input_ids = ids,\n",
    "              attention_mask = mask, \n",
    "              max_length=150, \n",
    "              num_beams=2,\n",
    "              repetition_penalty=2.5, \n",
    "              length_penalty=1.0, \n",
    "              early_stopping=True\n",
    "              )\n",
    "          preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "          target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
    "          if _%10==0:\n",
    "              console.print(f'Completed {_}')\n",
    "\n",
    "          predictions.extend(preds)\n",
    "          actuals.extend(target)\n",
    "  return predictions, actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Tw4RW_qO4_8T"
   },
   "outputs": [],
   "source": [
    "def T5Trainer(dataframe, source_text, target_text, model_params, output_dir=\"./outputs/\" ):\n",
    "  \n",
    "  # Set random seeds and deterministic pytorch for reproducibility\n",
    "  torch.manual_seed(model_params[\"SEED\"]) # pytorch random seed\n",
    "  np.random.seed(model_params[\"SEED\"]) # numpy random seed\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "\n",
    "  # logging\n",
    "  console.log(f\"\"\"[Model]: Loading {model_params[\"MODEL\"]}...\\n\"\"\")\n",
    "\n",
    "  # tokenzier for encoding the text\n",
    "  tokenizer = T5Tokenizer.from_pretrained(model_params[\"MODEL\"])\n",
    "\n",
    "  # Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary. \n",
    "  # Further this model is sent to device (GPU/TPU) for using the hardware.\n",
    "  model = T5ForConditionalGeneration.from_pretrained(model_params[\"MODEL\"])\n",
    "  model = model.to(device)\n",
    "  \n",
    "  # logging\n",
    "  console.log(f\"[Data]: Reading data...\\n\")\n",
    "\n",
    "  # Importing the raw dataset\n",
    "  dataframe = dataframe[[source_text,target_text]]\n",
    "  display_df(dataframe.head(2))\n",
    "\n",
    "  \n",
    "  # Creation of Dataset and Dataloader\n",
    "  # Defining the train size. So 80% of the data will be used for training and the rest for validation. \n",
    "  train_size = 0.8\n",
    "  train_dataset=dataframe.sample(frac=train_size,random_state = model_params[\"SEED\"])\n",
    "  val_dataset=dataframe.drop(train_dataset.index).reset_index(drop=True)\n",
    "  train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "  console.print(f\"FULL Dataset: {dataframe.shape}\")\n",
    "  console.print(f\"TRAIN Dataset: {train_dataset.shape}\")\n",
    "  console.print(f\"TEST Dataset: {val_dataset.shape}\\n\")\n",
    "\n",
    "\n",
    "  # Creating the Training and Validation dataset for further creation of Dataloader\n",
    "  training_set = YourDataSetClass(train_dataset, tokenizer, model_params[\"MAX_SOURCE_TEXT_LENGTH\"], model_params[\"MAX_TARGET_TEXT_LENGTH\"], source_text, target_text)\n",
    "  val_set = YourDataSetClass(val_dataset, tokenizer, model_params[\"MAX_SOURCE_TEXT_LENGTH\"], model_params[\"MAX_TARGET_TEXT_LENGTH\"], source_text, target_text)\n",
    "\n",
    "\n",
    "  # Defining the parameters for creation of dataloaders\n",
    "  train_params = {\n",
    "      'batch_size': model_params[\"TRAIN_BATCH_SIZE\"],\n",
    "      'shuffle': True,\n",
    "      'num_workers': 0\n",
    "      }\n",
    "\n",
    "\n",
    "  val_params = {\n",
    "      'batch_size': model_params[\"VALID_BATCH_SIZE\"],\n",
    "      'shuffle': False,\n",
    "      'num_workers': 0\n",
    "      }\n",
    "\n",
    "\n",
    "  # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
    "  training_loader = DataLoader(training_set, **train_params)\n",
    "  val_loader = DataLoader(val_set, **val_params)\n",
    "\n",
    "\n",
    "  # Defining the optimizer that will be used to tune the weights of the network in the training session. \n",
    "  optimizer = torch.optim.Adam(params =  model.parameters(), lr=model_params[\"LEARNING_RATE\"])\n",
    "\n",
    "\n",
    "  # Training loop\n",
    "  console.log(f'[Initiating Fine Tuning]...\\n')\n",
    "\n",
    "  for epoch in range(model_params[\"TRAIN_EPOCHS\"]):\n",
    "      train(epoch, tokenizer, model, device, training_loader, optimizer)\n",
    "      \n",
    "  console.log(f\"[Saving Model]...\\n\")\n",
    "  #Saving the model after training\n",
    "  path = os.path.join(output_dir, \"model_files\")\n",
    "  model.save_pretrained(path)\n",
    "  tokenizer.save_pretrained(path)\n",
    "\n",
    "\n",
    "  # evaluating test dataset\n",
    "  console.log(f\"[Initiating Validation]...\\n\")\n",
    "  for epoch in range(model_params[\"VAL_EPOCHS\"]):\n",
    "    predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
    "    final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
    "    final_df.to_csv(os.path.join(output_dir,'predictions.csv'))\n",
    "  \n",
    "  console.save_text(os.path.join(output_dir,'logs.txt'))\n",
    "  \n",
    "  console.log(f\"[Validation Completed.]\\n\")\n",
    "  console.print(f\"\"\"[Model] Model saved @ {os.path.join(output_dir, \"model_files\")}\\n\"\"\")\n",
    "  console.print(f\"\"\"[Validation] Generation on Validation data saved @ {os.path.join(output_dir,'predictions.csv')}\\n\"\"\")\n",
    "  console.print(f\"\"\"[Logs] Logs saved @ {os.path.join(output_dir,'logs.txt')}\\n\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "PxCpQwD8PDIs"
   },
   "outputs": [],
   "source": [
    "model_params={\n",
    "    \"MODEL\":\"t5-base\",             # model_type: t5-base/t5-large\n",
    "    \"TRAIN_BATCH_SIZE\":8,          # training batch size\n",
    "    \"VALID_BATCH_SIZE\":8,          # validation batch size\n",
    "    \"TRAIN_EPOCHS\":3,              # number of training epochs\n",
    "    \"VAL_EPOCHS\":1,                # number of validation epochs\n",
    "    \"LEARNING_RATE\":1e-4,          # learning rate\n",
    "    \"MAX_SOURCE_TEXT_LENGTH\":512,  # max length of source text\n",
    "    \"MAX_TARGET_TEXT_LENGTH\":50,   # max length of target text\n",
    "    \"SEED\": 42                     # set seed for reproducibility \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qijZoYeI55fM",
    "outputId": "69c68bb6-4fba-47e4-9e74-73f2579aa3c8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[13:35:52] </span><span style=\"font-weight: bold\">[</span>Model<span style=\"font-weight: bold\">]</span>: Loading t5-base<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                             <a href=\"file://C:\\Users\\Thirumalan\\AppData\\Local\\Temp\\ipykernel_29612\\2575154273.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2575154273.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\Thirumalan\\AppData\\Local\\Temp\\ipykernel_29612\\2575154273.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[13:35:52]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mModel\u001b[1m]\u001b[0m: Loading t5-base\u001b[33m...\u001b[0m                                                             \u001b]8;id=236139;file://C:\\Users\\Thirumalan\\AppData\\Local\\Temp\\ipykernel_29612\\2575154273.py\u001b\\\u001b[2m2575154273.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=961325;file://C:\\Users\\Thirumalan\\AppData\\Local\\Temp\\ipykernel_29612\\2575154273.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                                                                        \u001b[2m                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[13:35:56] </span><span style=\"font-weight: bold\">[</span>Data<span style=\"font-weight: bold\">]</span>: Reading data<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                 <a href=\"file://C:\\Users\\Thirumalan\\AppData\\Local\\Temp\\ipykernel_29612\\2575154273.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2575154273.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\Thirumalan\\AppData\\Local\\Temp\\ipykernel_29612\\2575154273.py#25\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">25</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[13:35:56]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mData\u001b[1m]\u001b[0m: Reading data\u001b[33m...\u001b[0m                                                                 \u001b]8;id=696897;file://C:\\Users\\Thirumalan\\AppData\\Local\\Temp\\ipykernel_29612\\2575154273.py\u001b\\\u001b[2m2575154273.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=286903;file://C:\\Users\\Thirumalan\\AppData\\Local\\Temp\\ipykernel_29612\\2575154273.py#25\u001b\\\u001b[2m25\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                                                                        \u001b[2m                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                    Sample Data                                                    </span>\n",
       "+-----------------------------------------------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">                      source_text                       </span>|<span style=\"font-weight: bold\">                       target_text                      </span>|\n",
       "|--------------------------------------------------------+--------------------------------------------------------|\n",
       "|  By . Associated Press . PUBLISHED: . 14:11 EST, 25    | Bishop John Folda, of North Dakota, is taking time off |\n",
       "|  October 2013 . | . UPDATED: . 15:36 EST, 25 October   |                 after being diagnosed .                |\n",
       "|  2013 . The bishop of the Fargo Catholic Diocese in    |  He contracted the infection through contaminated food |\n",
       "|North Dakota has exposed potentially hundreds of church |                       in Italy .                       |\n",
       "|  members in Fargo, Grand Forks and Jamestown to the    |   Church members in Fargo, Grand Forks and Jamestown   |\n",
       "|hepatitis A virus in late September and early October.  |                could have been exposed .               |\n",
       "| The state Health Department has issued an advisory of  |                                                        |\n",
       "|exposure for anyone who attended five churches and took |                                                        |\n",
       "| communion. Bishop John Folda (pictured) of the Fargo   |                                                        |\n",
       "|     Catholic Diocese in North Dakota has exposed       |                                                        |\n",
       "|potentially hundreds of church members in Fargo, Grand  |                                                        |\n",
       "|    Forks and Jamestown to the hepatitis A . State      |                                                        |\n",
       "|Immunization Program Manager Molly Howell says the risk |                                                        |\n",
       "|  is low, but officials feel it's important to alert    |                                                        |\n",
       "|people to the possible exposure. The diocese announced  |                                                        |\n",
       "|  on Monday that Bishop John Folda is taking time off   |                                                        |\n",
       "|  after being diagnosed with hepatitis A. The diocese   |                                                        |\n",
       "| says he contracted the infection through contaminated  |                                                        |\n",
       "| food while attending a conference for newly ordained   |                                                        |\n",
       "| bishops in Italy last month. Symptoms of hepatitis A   |                                                        |\n",
       "|include fever, tiredness, loss of appetite, nausea and  |                                                        |\n",
       "| abdominal discomfort. Fargo Catholic Diocese in North  |                                                        |\n",
       "|  Dakota (pictured) is where the bishop is located .    |                                                        |\n",
       "|(CNN) -- Ralph Mata was an internal affairs lieutenant  |  Criminal complaint: Cop used his role to help cocaine |\n",
       "| for the Miami-Dade Police Department, working in the   |                      traffickers .                     |\n",
       "|division that investigates allegations of wrongdoing by |  Ralph Mata, an internal affairs lieutenant, allegedly |\n",
       "| cops. Outside the office, authorities allege that the  |                 helped group get guns .                |\n",
       "|    45-year-old longtime officer worked with a drug     | He also arranged to pay two assassins in a murder plot,|\n",
       "|trafficking organization to help plan a murder plot and |                  a complaint alleges .                 |\n",
       "|    get guns. A criminal complaint unsealed in U.S.     |                                                        |\n",
       "|District Court in New Jersey Tuesday accuses Mata, also |                                                        |\n",
       "|known as \"The Milk Man,\" of using his role as a police  |                                                        |\n",
       "| officer to help the drug trafficking organization in   |                                                        |\n",
       "|exchange for money and gifts, including a Rolex watch.  |                                                        |\n",
       "| In one instance, the complaint alleges, Mata arranged  |                                                        |\n",
       "| to pay two assassins to kill rival drug dealers. The   |                                                        |\n",
       "|killers would pose as cops, pulling over their targets  |                                                        |\n",
       "|   before shooting them, according to the complaint.    |                                                        |\n",
       "|  \"Ultimately, the (organization) decided not to move   |                                                        |\n",
       "|forward with the murder plot, but Mata still received a |                                                        |\n",
       "|     payment for setting up the meetings,\" federal      |                                                        |\n",
       "|  prosecutors said in a statement. The complaint also   |                                                        |\n",
       "|  alleges that Mata used his police badge to purchase   |                                                        |\n",
       "| weapons for drug traffickers. Mata, according to the   |                                                        |\n",
       "|    complaint, then used contacts at the airport to     |                                                        |\n",
       "|transport the weapons in his carry-on luggage on trips  |                                                        |\n",
       "| from Miami to the Dominican Republic. Court documents  |                                                        |\n",
       "| released by investigators do not specify the name of   |                                                        |\n",
       "|   the drug trafficking organization with which Mata    |                                                        |\n",
       "|allegedly conspired but says the organization has been  |                                                        |\n",
       "|importing narcotics from places such as Ecuador and the |                                                        |\n",
       "|  Dominican Republic by hiding them \"inside shipping    |                                                        |\n",
       "|  containers containing pallets of produce, including   |                                                        |\n",
       "|   bananas.\" The organization \"has been distributing    |                                                        |\n",
       "| narcotics in New Jersey and elsewhere,\" the complaint  |                                                        |\n",
       "|  says. Authorities arrested Mata on Tuesday in Miami   |                                                        |\n",
       "|Gardens, Florida. It was not immediately clear whether  |                                                        |\n",
       "|Mata has an attorney, and police officials could not be |                                                        |\n",
       "| immediately reached for comment. Mata has worked for   |                                                        |\n",
       "|the Miami-Dade Police Department since 1992, including  |                                                        |\n",
       "| directing investigations in Miami Gardens and working  |                                                        |\n",
       "|as a lieutenant in the K-9 unit at Miami International  |                                                        |\n",
       "|Airport, according to the complaint. Since March 2010,  |                                                        |\n",
       "| he had been working in the internal affairs division.  |                                                        |\n",
       "|Mata faces charges of aiding and abetting a conspiracy  |                                                        |\n",
       "|to distribute cocaine, conspiring to distribute cocaine |                                                        |\n",
       "|   and engaging in monetary transactions in property    |                                                        |\n",
       "|    derived from specified unlawful activity. He is     |                                                        |\n",
       "|  scheduled to appear in federal court in Florida on    |                                                        |\n",
       "|   Wednesday. If convicted, Mata could face life in     |                                                        |\n",
       "|   prison. CNN's Suzanne Presto contributed to this     |                                                        |\n",
       "|                        report.                         |                                                        |\n",
       "+-----------------------------------------------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                    Sample Data                                                    \u001b[0m\n",
       "+-----------------------------------------------------------------------------------------------------------------+\n",
       "|\u001b[1m                      source_text                      \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                      target_text                      \u001b[0m|\n",
       "|--------------------------------------------------------+--------------------------------------------------------|\n",
       "|  By . Associated Press . PUBLISHED: . 14:11 EST, 25    | Bishop John Folda, of North Dakota, is taking time off |\n",
       "|  October 2013 . | . UPDATED: . 15:36 EST, 25 October   |                 after being diagnosed .                |\n",
       "|  2013 . The bishop of the Fargo Catholic Diocese in    |  He contracted the infection through contaminated food |\n",
       "|North Dakota has exposed potentially hundreds of church |                       in Italy .                       |\n",
       "|  members in Fargo, Grand Forks and Jamestown to the    |   Church members in Fargo, Grand Forks and Jamestown   |\n",
       "|hepatitis A virus in late September and early October.  |                could have been exposed .               |\n",
       "| The state Health Department has issued an advisory of  |                                                        |\n",
       "|exposure for anyone who attended five churches and took |                                                        |\n",
       "| communion. Bishop John Folda (pictured) of the Fargo   |                                                        |\n",
       "|     Catholic Diocese in North Dakota has exposed       |                                                        |\n",
       "|potentially hundreds of church members in Fargo, Grand  |                                                        |\n",
       "|    Forks and Jamestown to the hepatitis A . State      |                                                        |\n",
       "|Immunization Program Manager Molly Howell says the risk |                                                        |\n",
       "|  is low, but officials feel it's important to alert    |                                                        |\n",
       "|people to the possible exposure. The diocese announced  |                                                        |\n",
       "|  on Monday that Bishop John Folda is taking time off   |                                                        |\n",
       "|  after being diagnosed with hepatitis A. The diocese   |                                                        |\n",
       "| says he contracted the infection through contaminated  |                                                        |\n",
       "| food while attending a conference for newly ordained   |                                                        |\n",
       "| bishops in Italy last month. Symptoms of hepatitis A   |                                                        |\n",
       "|include fever, tiredness, loss of appetite, nausea and  |                                                        |\n",
       "| abdominal discomfort. Fargo Catholic Diocese in North  |                                                        |\n",
       "|  Dakota (pictured) is where the bishop is located .    |                                                        |\n",
       "|(CNN) -- Ralph Mata was an internal affairs lieutenant  |  Criminal complaint: Cop used his role to help cocaine |\n",
       "| for the Miami-Dade Police Department, working in the   |                      traffickers .                     |\n",
       "|division that investigates allegations of wrongdoing by |  Ralph Mata, an internal affairs lieutenant, allegedly |\n",
       "| cops. Outside the office, authorities allege that the  |                 helped group get guns .                |\n",
       "|    45-year-old longtime officer worked with a drug     | He also arranged to pay two assassins in a murder plot,|\n",
       "|trafficking organization to help plan a murder plot and |                  a complaint alleges .                 |\n",
       "|    get guns. A criminal complaint unsealed in U.S.     |                                                        |\n",
       "|District Court in New Jersey Tuesday accuses Mata, also |                                                        |\n",
       "|known as \"The Milk Man,\" of using his role as a police  |                                                        |\n",
       "| officer to help the drug trafficking organization in   |                                                        |\n",
       "|exchange for money and gifts, including a Rolex watch.  |                                                        |\n",
       "| In one instance, the complaint alleges, Mata arranged  |                                                        |\n",
       "| to pay two assassins to kill rival drug dealers. The   |                                                        |\n",
       "|killers would pose as cops, pulling over their targets  |                                                        |\n",
       "|   before shooting them, according to the complaint.    |                                                        |\n",
       "|  \"Ultimately, the (organization) decided not to move   |                                                        |\n",
       "|forward with the murder plot, but Mata still received a |                                                        |\n",
       "|     payment for setting up the meetings,\" federal      |                                                        |\n",
       "|  prosecutors said in a statement. The complaint also   |                                                        |\n",
       "|  alleges that Mata used his police badge to purchase   |                                                        |\n",
       "| weapons for drug traffickers. Mata, according to the   |                                                        |\n",
       "|    complaint, then used contacts at the airport to     |                                                        |\n",
       "|transport the weapons in his carry-on luggage on trips  |                                                        |\n",
       "| from Miami to the Dominican Republic. Court documents  |                                                        |\n",
       "| released by investigators do not specify the name of   |                                                        |\n",
       "|   the drug trafficking organization with which Mata    |                                                        |\n",
       "|allegedly conspired but says the organization has been  |                                                        |\n",
       "|importing narcotics from places such as Ecuador and the |                                                        |\n",
       "|  Dominican Republic by hiding them \"inside shipping    |                                                        |\n",
       "|  containers containing pallets of produce, including   |                                                        |\n",
       "|   bananas.\" The organization \"has been distributing    |                                                        |\n",
       "| narcotics in New Jersey and elsewhere,\" the complaint  |                                                        |\n",
       "|  says. Authorities arrested Mata on Tuesday in Miami   |                                                        |\n",
       "|Gardens, Florida. It was not immediately clear whether  |                                                        |\n",
       "|Mata has an attorney, and police officials could not be |                                                        |\n",
       "| immediately reached for comment. Mata has worked for   |                                                        |\n",
       "|the Miami-Dade Police Department since 1992, including  |                                                        |\n",
       "| directing investigations in Miami Gardens and working  |                                                        |\n",
       "|as a lieutenant in the K-9 unit at Miami International  |                                                        |\n",
       "|Airport, according to the complaint. Since March 2010,  |                                                        |\n",
       "| he had been working in the internal affairs division.  |                                                        |\n",
       "|Mata faces charges of aiding and abetting a conspiracy  |                                                        |\n",
       "|to distribute cocaine, conspiring to distribute cocaine |                                                        |\n",
       "|   and engaging in monetary transactions in property    |                                                        |\n",
       "|    derived from specified unlawful activity. He is     |                                                        |\n",
       "|  scheduled to appear in federal court in Florida on    |                                                        |\n",
       "|   Wednesday. If convicted, Mata could face life in     |                                                        |\n",
       "|   prison. CNN's Suzanne Presto contributed to this     |                                                        |\n",
       "|                        report.                         |                                                        |\n",
       "+-----------------------------------------------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">FULL Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "FULL Dataset: \u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TRAIN Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "TRAIN Dataset: \u001b[1m(\u001b[0m\u001b[1;36m400\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TEST Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "TEST Dataset: \u001b[1m(\u001b[0m\u001b[1;36m100\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">[</span>Initiating Fine Tuning<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                             <a href=\"file://C:\\Users\\Thirumalan\\AppData\\Local\\Temp\\ipykernel_29612\\2575154273.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2575154273.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\Thirumalan\\AppData\\Local\\Temp\\ipykernel_29612\\2575154273.py#74\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">74</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mInitiating Fine Tuning\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                                                             \u001b]8;id=66673;file://C:\\Users\\Thirumalan\\AppData\\Local\\Temp\\ipykernel_29612\\2575154273.py\u001b\\\u001b[2m2575154273.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=680019;file://C:\\Users\\Thirumalan\\AppData\\Local\\Temp\\ipykernel_29612\\2575154273.py#74\u001b\\\u001b[2m74\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                                                                        \u001b[2m                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                      Training Status                       </span>\n",
       "+----------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                    Loss                   </span>|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+----------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                      Training Status                       \u001b[0m\n",
       "+----------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                   Loss                   \u001b[0m|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=<NllLossBackward0>)|\n",
       "+----------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                      Training Status                       </span>\n",
       "+----------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                    Loss                   </span>|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(3.1071, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+----------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                      Training Status                       \u001b[0m\n",
       "+----------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                   Loss                   \u001b[0m|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(3.1071, grad_fn=<NllLossBackward0>)|\n",
       "+----------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                      Training Status                       </span>\n",
       "+----------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                    Loss                   </span>|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(3.1071, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.1603, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+----------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                      Training Status                       \u001b[0m\n",
       "+----------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                   Loss                   \u001b[0m|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(3.1071, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.1603, grad_fn=<NllLossBackward0>)|\n",
       "+----------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                      Training Status                       </span>\n",
       "+----------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                    Loss                   </span>|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(3.1071, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.1603, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.6085, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+----------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                      Training Status                       \u001b[0m\n",
       "+----------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                   Loss                   \u001b[0m|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(3.1071, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.1603, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.6085, grad_fn=<NllLossBackward0>)|\n",
       "+----------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                      Training Status                       </span>\n",
       "+----------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                    Loss                   </span>|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(3.1071, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.1603, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.6085, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(2.1834, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+----------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                      Training Status                       \u001b[0m\n",
       "+----------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                   Loss                   \u001b[0m|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(3.1071, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.1603, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.6085, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(2.1834, grad_fn=<NllLossBackward0>)|\n",
       "+----------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                      Training Status                       </span>\n",
       "+----------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                    Loss                   </span>|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(3.1071, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.1603, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.6085, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(2.1834, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.1039, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+----------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                      Training Status                       \u001b[0m\n",
       "+----------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                   Loss                   \u001b[0m|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(3.1071, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.1603, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.6085, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(2.1834, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.1039, grad_fn=<NllLossBackward0>)|\n",
       "+----------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                      Training Status                       </span>\n",
       "+----------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                    Loss                   </span>|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(3.1071, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.1603, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.6085, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(2.1834, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.1039, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(2.2931, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+----------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                      Training Status                       \u001b[0m\n",
       "+----------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                   Loss                   \u001b[0m|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(3.1071, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.1603, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.6085, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(2.1834, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.1039, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(2.2931, grad_fn=<NllLossBackward0>)|\n",
       "+----------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                      Training Status                       </span>\n",
       "+----------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                    Loss                   </span>|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(3.1071, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.1603, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.6085, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(2.1834, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.1039, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(2.2931, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.0351, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+----------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                      Training Status                       \u001b[0m\n",
       "+----------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                   Loss                   \u001b[0m|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(3.1071, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.1603, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.6085, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(2.1834, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.1039, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(2.2931, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.0351, grad_fn=<NllLossBackward0>)|\n",
       "+----------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                      Training Status                       </span>\n",
       "+----------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                    Loss                   </span>|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(3.1071, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.1603, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.6085, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(2.1834, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.1039, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(2.2931, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.0351, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.4066, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+----------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                      Training Status                       \u001b[0m\n",
       "+----------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                   Loss                   \u001b[0m|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(3.1071, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.1603, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.6085, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(2.1834, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.1039, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(2.2931, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.0351, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.4066, grad_fn=<NllLossBackward0>)|\n",
       "+----------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                      Training Status                       </span>\n",
       "+----------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                    Loss                   </span>|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(3.1071, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.1603, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.6085, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(2.1834, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.1039, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(2.2931, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.0351, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.4066, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.7661, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+----------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                      Training Status                       \u001b[0m\n",
       "+----------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                   Loss                   \u001b[0m|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(3.1071, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.1603, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.6085, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(2.1834, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.1039, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(2.2931, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.0351, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.4066, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.7661, grad_fn=<NllLossBackward0>)|\n",
       "+----------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                      Training Status                       </span>\n",
       "+----------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                    Loss                   </span>|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(3.1071, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.1603, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.6085, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(2.1834, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.1039, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(2.2931, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.0351, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.4066, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.7661, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.7307, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+----------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                      Training Status                       \u001b[0m\n",
       "+----------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                   Loss                   \u001b[0m|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(3.1071, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.1603, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.6085, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(2.1834, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.1039, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(2.2931, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.0351, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.4066, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.7661, grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.7307, grad_fn=<NllLossBackward0>)|\n",
       "+----------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                      Training Status                       </span>\n",
       "+----------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                    Loss                   </span>|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(3.1071, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.1603, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.6085, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(2.1834, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.1039, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(2.2931, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.0351, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.4066, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.7661, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.7307, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.3119, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+----------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                      Training Status                       \u001b[0m\n",
       "+----------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                   Loss                   \u001b[0m|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(3.1071, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.1603, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.6085, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(2.1834, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.1039, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(2.2931, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.0351, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.4066, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.7661, grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.7307, grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.3119, grad_fn=<NllLossBackward0>)|\n",
       "+----------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                      Training Status                       </span>\n",
       "+----------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                    Loss                   </span>|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(3.1071, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.1603, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.6085, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(2.1834, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.1039, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(2.2931, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.0351, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.4066, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.7661, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.7307, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.3119, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7978, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+----------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                      Training Status                       \u001b[0m\n",
       "+----------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                   Loss                   \u001b[0m|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(3.1071, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.1603, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.6085, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(2.1834, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.1039, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(2.2931, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.0351, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.4066, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.7661, grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.7307, grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.3119, grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7978, grad_fn=<NllLossBackward0>)|\n",
       "+----------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                      Training Status                       </span>\n",
       "+----------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                    Loss                   </span>|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(3.1071, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.1603, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.6085, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(2.1834, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.1039, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(2.2931, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.0351, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.4066, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.7661, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.7307, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.3119, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7978, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(1.8544, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+----------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                      Training Status                       \u001b[0m\n",
       "+----------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                   Loss                   \u001b[0m|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(3.1071, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.1603, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.6085, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(2.1834, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.1039, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(2.2931, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.0351, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.4066, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.7661, grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.7307, grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.3119, grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7978, grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(1.8544, grad_fn=<NllLossBackward0>)|\n",
       "+----------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                      Training Status                       </span>\n",
       "+----------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                    Loss                   </span>|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(3.1071, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.1603, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.6085, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(2.1834, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.1039, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(2.2931, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.0351, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.4066, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.7661, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.7307, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.3119, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7978, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(1.8544, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.7303, grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+----------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                      Training Status                       \u001b[0m\n",
       "+----------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                   Loss                   \u001b[0m|\n",
       "|------+-------+-------------------------------------------|\n",
       "|  0   |   0   | tensor(7.5917, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(7.1012, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(3.1071, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.1603, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.6085, grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(2.1834, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.1039, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(2.2931, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.0351, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.4066, grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.7661, grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.7307, grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.3119, grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7978, grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(1.8544, grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.7303, grad_fn=<NllLossBackward0>)|\n",
       "+----------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:42:32] </span><span style=\"font-weight: bold\">[</span>Saving Model<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                       <a href=\"file://C:\\Users\\Thirumalan\\AppData\\Local\\Temp\\ipykernel_29612\\2575154273.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2575154273.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\Thirumalan\\AppData\\Local\\Temp\\ipykernel_29612\\2575154273.py#79\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">79</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:42:32]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mSaving Model\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                                                                       \u001b]8;id=304998;file://C:\\Users\\Thirumalan\\AppData\\Local\\Temp\\ipykernel_29612\\2575154273.py\u001b\\\u001b[2m2575154273.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=335487;file://C:\\Users\\Thirumalan\\AppData\\Local\\Temp\\ipykernel_29612\\2575154273.py#79\u001b\\\u001b[2m79\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                                                                        \u001b[2m                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:42:33] </span><span style=\"font-weight: bold\">[</span>Initiating Validation<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                              <a href=\"file://C:\\Users\\Thirumalan\\AppData\\Local\\Temp\\ipykernel_29612\\2575154273.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2575154273.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\Thirumalan\\AppData\\Local\\Temp\\ipykernel_29612\\2575154273.py#87\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">87</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:42:33]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mInitiating Validation\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                                                              \u001b]8;id=125436;file://C:\\Users\\Thirumalan\\AppData\\Local\\Temp\\ipykernel_29612\\2575154273.py\u001b\\\u001b[2m2575154273.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=710287;file://C:\\Users\\Thirumalan\\AppData\\Local\\Temp\\ipykernel_29612\\2575154273.py#87\u001b\\\u001b[2m87\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                                                                        \u001b[2m                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m10\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:47:42] </span><span style=\"font-weight: bold\">[</span>Validation Completed.<span style=\"font-weight: bold\">]</span>                                                                 <a href=\"file://C:\\Users\\Thirumalan\\AppData\\Local\\Temp\\ipykernel_29612\\2575154273.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2575154273.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\Thirumalan\\AppData\\Local\\Temp\\ipykernel_29612\\2575154273.py#95\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">95</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:47:42]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mValidation Completed.\u001b[1m]\u001b[0m                                                                 \u001b]8;id=644207;file://C:\\Users\\Thirumalan\\AppData\\Local\\Temp\\ipykernel_29612\\2575154273.py\u001b\\\u001b[2m2575154273.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=830976;file://C:\\Users\\Thirumalan\\AppData\\Local\\Temp\\ipykernel_29612\\2575154273.py#95\u001b\\\u001b[2m95\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                                                                        \u001b[2m                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Model<span style=\"font-weight: bold\">]</span> Model saved @ outputs\\model_files\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mModel\u001b[1m]\u001b[0m Model saved @ outputs\\model_files\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Validation<span style=\"font-weight: bold\">]</span> Generation on Validation data saved @ outputs\\predictions.csv\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mValidation\u001b[1m]\u001b[0m Generation on Validation data saved @ outputs\\predictions.csv\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Logs<span style=\"font-weight: bold\">]</span> Logs saved @ outputs\\logs.txt\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mLogs\u001b[1m]\u001b[0m Logs saved @ outputs\\logs.txt\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "T5Trainer(dataframe=df[:500], source_text=\"target_text\", target_text=\"source_text\", model_params=model_params, output_dir=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XD2qL87Wsn19"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u7SFz-6usqym"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM+sqU2Hgca8RM/Wjv+9kvQ",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "T5 Fine tuning with PyTorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
